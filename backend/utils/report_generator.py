from fpdf import FPDF
from datetime import datetime
from config import Config
import os
from utils.nlp_utils import NLPPipeline

class ReportGenerator:
    def __init__(self):
        self.nlp = NLPPipeline()
        self.report_font = 'Arial'
        self.primary_color = (67, 97, 238)  # #4361ee
        self.secondary_color = (63, 55, 201)  # #3f37c9
        
    def generate(self, analysis_data):
        """
        Generate comprehensive PDF report from analysis data
        """
        pdf = FPDF()
        pdf.set_auto_page_break(auto=True, margin=15)
        
        # Set document metadata
        pdf.set_title(Config.REPORT_TITLE)
        pdf.set_author(Config.REPORT_AUTHOR)
        
        # Add cover page
        self._add_cover_page(pdf, analysis_data)
        
        # Add summary page
        pdf.add_page()
        self._add_summary_page(pdf, analysis_data)
        
        # Add detailed analysis
        pdf.add_page()
        self._add_detailed_analysis(pdf, analysis_data)
        
        # Add file previews
        pdf.add_page()
        self._add_file_previews(pdf, analysis_data)
        
        # Add matches if they exist
        if analysis_data['results'].get('matches'):
            pdf.add_page()
            self._add_matches_page(pdf, analysis_data)
        
        # Save the PDF
        os.makedirs('reports', exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = f"reports/report_{timestamp}.pdf"
        pdf.output(report_path)
        
        return report_path
    
    def _add_cover_page(self, pdf, data):
        pdf.add_page()
        
        # Add title
        pdf.set_font(self.report_font, 'B', 24)
        pdf.set_text_color(*self.primary_color)
        pdf.cell(0, 40, Config.REPORT_TITLE, 0, 1, 'C')
        
        # Add subtitle
        pdf.set_font(self.report_font, '', 16)
        pdf.set_text_color(0, 0, 0)
        pdf.cell(0, 20, "Plagiarism Analysis Report", 0, 1, 'C')
        
        # Add analysis date
        pdf.set_font(self.report_font, '', 12)
        analysis_date = datetime.fromisoformat(data['timestamp']).strftime('%B %d, %Y at %H:%M')
        pdf.cell(0, 10, f"Generated on: {analysis_date}", 0, 1, 'C')
        
        # Add file information
        pdf.ln(20)
        pdf.set_font(self.report_font, 'B', 14)
        pdf.cell(0, 10, "Files Analyzed:", 0, 1)
        
        pdf.set_font(self.report_font, '', 12)
        pdf.cell(0, 10, f"File 1: {data['file1_name']}", 0, 1)
        pdf.cell(0, 10, f"File 2: {data['file2_name']}", 0, 1)
        
        # Add overall score with visual indicator
        pdf.ln(15)
        self._add_score_indicator(pdf, data['results']['score'])
        
        # Add footer
        pdf.set_y(-30)
        pdf.set_font(self.report_font, 'I', 10)
        pdf.cell(0, 10, "Confidential Report - Generated by Plagiarism Detector", 0, 0, 'C')
    
    def _add_summary_page(self, pdf, data):
        pdf.set_font(self.report_font, 'B', 18)
        pdf.set_text_color(*self.primary_color)
        pdf.cell(0, 10, "Analysis Summary", 0, 1)
        pdf.ln(10)
        
        # Risk assessment
        score = data['results']['score']
        if score > 0.75:
            risk = "High Risk of Plagiarism"
            explanation = "The documents show significant similarity, indicating potential plagiarism."
        elif score > 0.5:
            risk = "Moderate Risk of Plagiarism"
            explanation = "The documents share substantial similarities that warrant further review."
        elif score > 0.25:
            risk = "Low Risk of Plagiarism"
            explanation = "Some similarities were found, but they may be coincidental."
        else:
            risk = "Minimal Similarity"
            explanation = "The documents show little to no significant similarity."
        
        pdf.set_font(self.report_font, 'B', 14)
        pdf.set_text_color(0, 0, 0)
        pdf.cell(0, 10, "Risk Assessment:", 0, 1)
        
        pdf.set_font(self.report_font, '', 12)
        pdf.multi_cell(0, 8, f"{risk}: {explanation}", 0, 1)
        pdf.ln(5)
        
        # Key metrics table
        self._add_metrics_table(pdf, data['results']['details'])
        
        # Key findings
        pdf.set_font(self.report_font, 'B', 14)
        pdf.cell(0, 10, "Key Findings:", 0, 1)
        
        pdf.set_font(self.report_font, '', 12)
        findings = [
            f"Highest similarity metric: {max(data['results']['details'].items(), key=lambda x: x[1])[0].replace('_', ' ').title()}",
            f"Longest matching section: {int(data['results'].get('longest_match', 0)*100)}% of document length",
            f"Document type: {'Code' if data['type'] in ['python', 'java', 'cpp'] else 'Text'} comparison"
        ]
        
        for finding in findings:
            pdf.cell(0, 8, "â€¢ " + finding, 0, 1)
    
    def _add_detailed_analysis(self, pdf, data):
        pdf.set_font(self.report_font, 'B', 18)
        pdf.set_text_color(*self.primary_color)
        pdf.cell(0, 10, "Detailed Analysis", 0, 1)
        pdf.ln(10)
        
        # Add metric explanations
        pdf.set_font(self.report_font, 'B', 14)
        pdf.cell(0, 10, "Similarity Metrics Explained:", 0, 1)
        
        metric_descriptions = {
            'jaccard': "Measures overlap of unique words between documents",
            'cosine': "Compares document vectors using TF-IDF weighting",
            'levenshtein': "Calculates edit distance between texts",
            'minhash': "Estimates similarity using probabilistic hashing",
            'semantic': "Uses AI to understand meaning similarity",
            'ast_similarity': "Compares abstract syntax tree structures (code only)",
            'function_similarity': "Analyzes function/method signatures (code only)"
        }
        
        pdf.set_font(self.report_font, '', 12)
        for metric, value in data['results']['details'].items():
            desc = metric_descriptions.get(metric, "Custom similarity metric")
            pdf.cell(90, 8, f"{metric.replace('_', ' ').title()}:", 0, 0)
            pdf.cell(30, 8, f"{value*100:.1f}%", 0, 0, 'R')
            pdf.multi_cell(0, 8, desc, 0, 1)
            pdf.ln(2)
        
        # Add NLP insights if text analysis
        if data['type'] == 'text':
            pdf.add_page()
            pdf.set_font(self.report_font, 'B', 14)
            pdf.cell(0, 10, "Text Analysis Insights:", 0, 1)
            
            combined_text = data['file1_preview'] + " " + data['file2_preview']
            key_phrases = self.nlp.extract_key_phrases(combined_text)
            readability = self.nlp.calculate_readability(combined_text)
            
            pdf.set_font(self.report_font, '', 12)
            pdf.cell(0, 8, "Key phrases found in documents:", 0, 1)
            pdf.set_font(self.report_font, 'I', 12)
            pdf.multi_cell(0, 8, ", ".join(key_phrases), 0, 1)
            pdf.ln(5)
            
            pdf.set_font(self.report_font, '', 12)
            pdf.cell(0, 8, f"Readability score: {readability:.1f} (Flesch Reading Ease)", 0, 1)
            pdf.cell(0, 8, self._interpret_readability(readability), 0, 1)
    
    def _add_file_previews(self, pdf, data):
        pdf.set_font(self.report_font, 'B', 18)
        pdf.set_text_color(*self.primary_color)
        pdf.cell(0, 10, "Document Previews", 0, 1)
        pdf.ln(10)
        
        # File 1 preview
        self._add_file_preview(pdf, data['file1_name'], data['file1_preview'])
        pdf.ln(10)
        
        # File 2 preview
        self._add_file_preview(pdf, data['file2_name'], data['file2_preview'])
    
    def _add_matches_page(self, pdf, data):
        pdf.set_font(self.report_font, 'B', 18)
        pdf.set_text_color(*self.primary_color)
        pdf.cell(0, 10, "Matched Sections", 0, 1)
        pdf.ln(10)
        
        pdf.set_font(self.report_font, '', 12)
        pdf.multi_cell(0, 8, "The following sections show significant similarity between the documents:", 0, 1)
        pdf.ln(5)
        
        for i, match in enumerate(data['results']['matches'][:5]):  # Limit to top 5 matches
            if pdf.get_y() > 250:  # Prevent overflow
                pdf.add_page()
                pdf.set_y(20)
            
            pdf.set_font(self.report_font, 'B', 12)
            pdf.cell(0, 8, f"Match #{i+1} - Similarity: {match['similarity']*100:.1f}%", 0, 1)
            
            pdf.set_font(self.report_font, '', 10)
            pdf.multi_cell(0, 6, f"File 1 (Position {match['text1_start']}-{match['text1_end']}):", 0, 1)
            pdf.set_font(self.report_font, '', 10)
            pdf.multi_cell(0, 6, data['file1_preview'][match['text1_start']:match['text1_end']], 0, 1)
            pdf.ln(2)
            
            pdf.set_font(self.report_font, '', 10)
            pdf.multi_cell(0, 6, f"File 2 (Position {match['text2_start']}-{match['text2_end']}):", 0, 1)
            pdf.set_font(self.report_font, '', 10)
            pdf.multi_cell(0, 6, data['file2_preview'][match['text2_start']:match['text2_end']], 0, 1)
            pdf.ln(8)
    
    def _add_score_indicator(self, pdf, score):
        pdf.set_font(self.report_font, 'B', 16)
        pdf.cell(0, 10, f"Overall Similarity Score: {score*100:.1f}%", 0, 1, 'C')
        
        # Add colored bar
        pdf.set_fill_color(200, 200, 200)  # Gray background
        pdf.rect(50, pdf.get_y(), 110, 10, 'F')
        
        # Set fill color based on score
        if score > 0.75:
            pdf.set_fill_color(247, 37, 133)  # Red
        elif score > 0.5:
            pdf.set_fill_color(248, 150, 30)  # Orange
        elif score > 0.25:
            pdf.set_fill_color(76, 201, 240)  # Blue
        else:
            pdf.set_fill_color(144, 190, 109)  # Green
            
        pdf.rect(50, pdf.get_y(), 110 * score, 10, 'F')
        pdf.ln(15)
    
    def _add_metrics_table(self, pdf, metrics):
        pdf.set_fill_color(*self.primary_color)
        pdf.set_text_color(255, 255, 255)
        pdf.set_font(self.report_font, 'B', 12)
        
        # Table header
        pdf.cell(100, 10, "Metric", 1, 0, 'C', True)
        pdf.cell(40, 10, "Score", 1, 1, 'C', True)
        
        # Table rows
        pdf.set_text_color(0, 0, 0)
        pdf.set_font(self.report_font, '', 12)
        
        for metric, value in metrics.items():
            # Alternate row colors
            if list(metrics.keys()).index(metric) % 2 == 0:
                pdf.set_fill_color(240, 240, 240)
            else:
                pdf.set_fill_color(255, 255, 255)
                
            pdf.cell(100, 10, metric.replace('_', ' ').title(), 1, 0, 'L', True)
            pdf.cell(40, 10, f"{value*100:.1f}%", 1, 1, 'C', True)
        
        pdf.set_fill_color(255, 255, 255)  # Reset fill color
    
    def _add_file_preview(self, pdf, filename, content):
        pdf.set_font(self.report_font, 'B', 14)
        pdf.cell(0, 10, filename, 0, 1)
        
        pdf.set_font(self.report_font, '', 10)
        pdf.set_draw_color(200, 200, 200)
        pdf.set_fill_color(245, 245, 245)
        pdf.multi_cell(0, 6, content, 1, 1, 'L', True)
    
    def _interpret_readability(self, score):
        if score >= 90:
            return "Very easy to read (5th grade level)"
        elif score >= 80:
            return "Easy to read (6th grade level)"
        elif score >= 70:
            return "Fairly easy to read (7th-8th grade level)"
        elif score >= 60:
            return "Plain English (9th-10th grade level)"
        elif score >= 50:
            return "Fairly difficult to read (college level)"
        elif score >= 30:
            return "Difficult to read (college graduate level)"
        else:
            return "Very difficult to read (professional level)"